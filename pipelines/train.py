import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from pathlib import Path
import time
import json
import signal
import sys
import os
import argparse
from torch.utils.tensorboard import SummaryWriter
import editdistance
import torchvision.utils as vutils
import random

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))
from core.dataset import create_dataloaders
from core.model import create_model

"""
Scale OCR Training Script

This script trains the CRNN model on the dataset prepared by the training_scripts.

WORKFLOW:
1. Prepare Images:
   python training_scripts/extract_frames.py --video_dir /path/to/videos

2. Split Labels:
   python training_scripts/split_data.py

3. Train Model:
   python train.py
   # Or with custom paths/params:
   python train.py --data-dir /content/data --save-dir /content/drive/MyDrive/models --batch-size 64

4. Validate:
   python training_scripts/validate.py

EXPECTED DIRECTORY STRUCTURE:
VideoWeightTool/
├── dataset.py
├── model.py
├── train.py
├── training_scripts/
│   ├── extract_frames.py
│   ├── split_data.py
│   └── validate.py
├── data/
│   ├── images/         (Generated by extract_frames.py)
│   └── labels/         (Generated by split_data.py)
└── models/             (Created automatically)
"""

def seed_everything(seed=42):
    """
    Set random seeds for reproducibility
    """
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

class SignalHandler:
    """
    Handles SIGINT (Ctrl+C) to allow for graceful shutdown
    """
    def __init__(self):
        self.received_signal = False
        signal.signal(signal.SIGINT, self._signal_handler)

    def _signal_handler(self, signal, frame):
        print("\n\n" + "!" * 60)
        print("RECEIVED SIGNAL INTERRUPT (Ctrl+C)")
        print("Finishing current epoch and saving progress...")
        print("!" * 60 + "\n")
        self.received_signal = True

class CTCLabelEncoder:
    """
    Encode text labels to indices for CTC loss
    Handles conversion between strings like "7.535" and tensor indices
    """
    def __init__(self):
        self.char_to_idx = {
            '0': 0, '1': 1, '2': 2, '3': 3, '4': 4,
            '5': 5, '6': 6, '7': 7, '8': 8, '9': 9,
            '.': 10
        }
        self.idx_to_char = {v: k for k, v in self.char_to_idx.items()}
        self.blank_label = 11
    
    def encode(self, text):
        return [self.char_to_idx[c] for c in text if c in self.char_to_idx]
    
    def encode_batch(self, texts):

        encoded = [self.encode(text) for text in texts]
        target_lengths = torch.LongTensor([len(enc) for enc in encoded])
        
        # Concatenate all targets into single tensor (required by CTC loss)
        targets = torch.cat([torch.LongTensor(enc) for enc in encoded])
        
        return targets, target_lengths


def train_one_epoch(model, train_loader, criterion, optimizer, encoder, device, epoch, scaler=None, accumulation_steps=1, writer=None):
    """
    Train for one epoch with mixed precision support and gradient accumulation
    
    Args:
        model: The neural network
        train_loader: DataLoader for training data
        criterion: Loss function (CTCLoss)
        optimizer: Optimizer (Adam)
        encoder: Label encoder
        device: 'cpu' or 'cuda'
        epoch: Current epoch number
        scaler: GradScaler for mixed precision training (optional)
        accumulation_steps: Number of batches to accumulate gradients over
    
    Returns:
        avg_loss: Average loss for the epoch
    """
    # Initialize signal handler at the start of training
    # We need to pass this to the workers or handle it globally
    # For now, we rely on the global handler check in the main loop
    
    model.train()  # Set to training mode
    
    total_loss = 0
    num_batches = len(train_loader)
    
    print(f"\nEpoch {epoch} - Training")
    print("-" * 60)
    
    start_time = time.time()
    
    optimizer.zero_grad()
    
    # We need to access the signal handler from the outer scope or pass it in
    # Since we didn't pass it, we'll check the module-level signal handler if possible
    # or just rely on the KeyboardInterrupt being caught in the main loop
    
    for batch_idx, (images, weights, filenames) in enumerate(train_loader):
        images = images.to(device)
        
        targets, target_lengths = encoder.encode_batch(weights)
        targets = targets.to(device)
        target_lengths = target_lengths.to(device)
        
        # Forward pass with automatic mixed precision
        if scaler is not None:
            with torch.amp.autocast(device.type):
                log_probs, output_lengths = model(images)
                output_lengths = output_lengths.to(device)
                loss = criterion(log_probs, targets, output_lengths, target_lengths)
                loss = loss / accumulation_steps
        else:
            log_probs, output_lengths = model(images)
            output_lengths = output_lengths.to(device)
            loss = criterion(log_probs, targets, output_lengths, target_lengths)
            loss = loss / accumulation_steps
        
        if writer is not None and (batch_idx + 1) % accumulation_steps == 0:
            # Calculate global step for continuous x-axis
            global_step = (epoch * num_batches) + batch_idx
            # We multiply by accumulation_steps because loss was divided by it earlier
            current_loss = loss.item() * accumulation_steps
            writer.add_scalar('Train/Batch_Loss', current_loss, global_step)
            writer.add_scalar('Train/Learning_Rate', optimizer.param_groups[0]['lr'], global_step)

        if torch.isnan(loss):
            print(f"Warning: NaN loss detected at batch {batch_idx}")
            continue
        
        if scaler is not None:
            scaler.scale(loss).backward()
        else:
            loss.backward()
        
        if (batch_idx + 1) % accumulation_steps == 0:
            if scaler is not None:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
                optimizer.step()
            
            optimizer.zero_grad()
        
        total_loss += loss.item() * accumulation_steps
        
        if (batch_idx + 1) % 10 == 0:
            avg_loss_so_far = total_loss / (batch_idx + 1)
            elapsed = time.time() - start_time
            batches_per_sec = (batch_idx + 1) / elapsed
            
            print(f"  Batch [{batch_idx+1}/{num_batches}] | "
                  f"Loss: {loss.item() * accumulation_steps:.4f} | "
                  f"Avg Loss: {avg_loss_so_far:.4f} | "
                  f"Speed: {batches_per_sec:.2f} batch/s")
    
    if len(train_loader) % accumulation_steps != 0:
        if scaler is not None:
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
            optimizer.step()
        optimizer.zero_grad()
    
    avg_loss = total_loss / num_batches
    epoch_time = time.time() - start_time
    
    print(f"\nEpoch {epoch} Training Complete:")
    print(f"  Average Loss: {avg_loss:.4f}")
    print(f"  Time: {epoch_time:.2f}s")
    
    return avg_loss


def log_visual_validation(writer, epoch, images, targets, predictions):
    """
    Makes a grid of images with their predicted vs actual labels and logs to TensorBoard.
    """
    if writer is None:
        return

    # vutils.make_grid expects BxCxHxW
    img_grid = vutils.make_grid(images[:8], normalize=True)
    writer.add_image('Validation/Images', img_grid, epoch)
    
    # Create a text string for the first few samples
    text_log = "### Validation Samples\n\n| Index | Ground Truth | Prediction | Status |\n|:---:|:---:|:---:|:---:|\n"
    for i in range(min(len(images), 8)):
        status = "Match" if targets[i] == predictions[i] else "Mismatch"
        # Escape pipes in text if any
        gt = str(targets[i]).replace('|', r'\|')
        pred = str(predictions[i]).replace('|', r'\|')
        text_log += f"| {i} | `{gt}` | `{pred}` | {status} |\n"
    
    writer.add_text('Validation/Predictions', text_log, epoch)

def calculate_metrics(predictions, targets):
    char_errors = 0
    total_chars = 0
    word_errors = 0
    
    for pred, gt in zip(predictions, targets):
        total_chars += len(gt)
        char_errors += editdistance.eval(pred, gt)
        
        if pred != gt:
            word_errors += 1
            
    cer = char_errors / max(1, total_chars)
    wer = word_errors / max(1, len(targets))
    return cer, wer

def validate(model, val_loader, criterion, encoder, device, epoch):
    """
    Validate the model
    
    Args:
        model: The neural network
        val_loader: DataLoader for validation data
        criterion: Loss function (CTCLoss)
        encoder: Label encoder
        device: 'cpu' or 'cuda'
        epoch: Current epoch number
    
    Returns:
        avg_loss, char_accuracy, seq_accuracy, cer, wer, vis_images, vis_targets, vis_preds
    """
    model.eval()  # Set to evaluation mode
    
    total_loss = 0
    
    all_predictions = []
    all_targets = []
    vis_images = None
    
    print(f"\nEpoch {epoch} - Validation")
    print("-" * 60)
    
    with torch.no_grad():  # No gradient computation during validation
        for batch_idx, (images, weights, filenames) in enumerate(val_loader):
            images = images.to(device)
            
            targets, target_lengths = encoder.encode_batch(weights)
            targets = targets.to(device)
            target_lengths = target_lengths.to(device)
            
            log_probs, output_lengths = model(images)
            output_lengths = output_lengths.to(device)
            
            loss = criterion(log_probs, targets, output_lengths, target_lengths)
            
            if not torch.isnan(loss):
                total_loss += loss.item()
            
            # use a slightly larger max_length 
            max_len = max(len(w) for w in weights) if len(weights) > 0 else 10
            predictions = model.decode_predictions(log_probs, max_length=max_len + 5)
            
            all_predictions.extend(predictions)
            all_targets.extend(weights)
            
            # Capture first batch for visualization
            if batch_idx == 0:
                vis_images = images.cpu()
    
    avg_loss = total_loss / len(val_loader)
    
    cer, wer = calculate_metrics(all_predictions, all_targets)
    seq_accuracy = (1 - wer) * 100
    char_accuracy = (1 - cer) * 100
    
    print(f"\nValidation Results:")
    print(f"  Loss: {avg_loss:.4f}")
    print(f"  CER: {cer:.4f} (Accuracy: {char_accuracy:.2f}%)")
    print(f"  WER: {wer:.4f} (Accuracy: {seq_accuracy:.2f}%)")
    
    print(f"\nExample Predictions:")
    num_examples = min(5, len(all_predictions))
    for i in range(num_examples):
        status = "Match" if all_predictions[i] == all_targets[i] else "Mismatch"
        print(f"  {status} Pred: '{all_predictions[i]}' | Target: '{all_targets[i]}'")
    
    return avg_loss, char_accuracy, seq_accuracy, cer, wer, vis_images, all_targets[:8], all_predictions[:8]


def train_model(
    batch_size=16,
    num_epochs=50,
    learning_rate=0.001,
    hidden_size=256,
    num_lstm_layers=2,
    image_size=(256, 64),
    save_dir='data/models',
    data_dir='data',
    resume_from=None,
    use_amp=True,
    seed=42,
    run_name=None
):
    """
    Main training function
    
    Args:
        train_dir: Path to training data
        val_dir: Path to validation data
        test_dir: Path to test data (optional)
        batch_size: Batch size for training
        num_epochs: Number of training epochs
        learning_rate: Learning rate for optimizer
        hidden_size: LSTM hidden size
        num_lstm_layers: Number of LSTM layers
        image_size: (width, height) for image resizing
        save_dir: Directory to save models
        data_dir: Directory containing data
        resume_from: Path to checkpoint to resume from (optional)
        seed: Random seed for reproducibility
        run_name: Name for the run (tensorboard logging)
    """
    seed_everything(seed)
    signal_handler = SignalHandler()
    save_path = Path(save_dir)
    save_path.mkdir(exist_ok=True, parents=True)

    # initialize tensorboard writer 
    # creates the folder 'runs/scale_ocr_{timestamp}'
    timestamp = time.strftime('%Y%m%d-%H%M%S')
    if run_name:
        run_name_clean = ""
        for c in run_name:
            if c.isalnum() or c in "-_":
                run_name_clean += c
        log_dir = f"runs/{run_name_clean}_{timestamp}"
    else:
        log_dir = f"runs/scale_ocr_{timestamp}"

    writer = SummaryWriter(log_dir=log_dir)
    print(f"TensorBoard logging to: {log_dir}")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\n{'='*60}")
    print(f"TRAINING SCALE OCR MODEL")
    print(f"{'='*60}")
    print(f"Device: {device}")
    print(f"Batch size: {batch_size}")
    print(f"Learning rate: {learning_rate}")
    print(f"Epochs: {num_epochs}")
    print(f"Image size: {image_size}")
    print(f"Data dir: {data_dir}")
    print(f"Save dir: {save_dir}")
    print(f"Seed: {seed}")
    print(f"{'='*60}\n")
    
    print("Loading data...")
    # Use number of CPUs for workers, but cap at 8 to avoid overhead
    num_workers = min(os.cpu_count() or 2, 8)
    
    train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        num_workers=num_workers,
        persistent_workers=True,
        prefetch_factor=2
    )
    
    print(f"\nDataset sizes:")
    print(f"  Train: {len(train_dataset)} samples")
    print(f"  Val: {len(val_dataset)} samples")
    if test_dataset:
        print(f"  Test: {len(test_dataset)} samples")

    encoder = CTCLabelEncoder()
    
    print("\nCreating model...")
    model = create_model(
        num_chars=len(encoder.char_to_idx),
        hidden_size=hidden_size,
        num_lstm_layers=num_lstm_layers,
        device=device.type
    )

    # Log model graph to Tensorboard
    try:
        dummy_input = torch.zeros(1, 3, image_size[1], image_size[0]).to(device)
        writer.add_graph(model, dummy_input)
    except Exception as e:
        print(f"Warning: Failed to add graph to TensorBoard: {e}")

    if hasattr(torch, 'compile'):
        try:
            print("Attempting to compile model with torch.compile()...")
            model = torch.compile(model)
        except Exception as e:
            print(f"Warning: torch.compile() failed, continuing without compile: {e}")
    
    criterion = nn.CTCLoss(blank=encoder.blank_label, zero_infinity=True)
    
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # Only use GradScaler if on CUDA
    scaler = torch.amp.GradScaler('cuda') if use_amp and device.type == 'cuda' else None
    
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=8
    )
    
    best_val_loss = float('inf')
    best_seq_accuracy = 0.0
    start_epoch = 0
    final_metrics_hparams = {}
    
    if resume_from and Path(resume_from).exists():
        print(f"\nResuming from checkpoint: {resume_from}")
        checkpoint = torch.load(resume_from, map_location=device)
        state_dict = checkpoint['model_state_dict']
        
        # Handle torch.compile prefix based on model's compiled state
        fixed_state_dict = {}
        model_has_orig = hasattr(model, '_orig_mod')  # Check if model is compiled
        
        for k, v in state_dict.items():
            if k.startswith('_orig_mod.'):
                if model_has_orig:
                    fixed_state_dict[k] = v  # Keep prefix if model is compiled
                else:
                    fixed_state_dict[k[len('_orig_mod.'):]] = v  # Strip prefix if model is not compiled
            else:
                if model_has_orig:
                    fixed_state_dict['_orig_mod.' + k] = v  # Add prefix if model is compiled
                else:
                    fixed_state_dict[k] = v  # Keep as-is if model is not compiled
        
        model.load_state_dict(fixed_state_dict)
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        # Load scheduler state if available
        if 'scheduler_state_dict' in checkpoint:
             scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        start_epoch = checkpoint['epoch'] + 1
        best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        print(f"Resumed from epoch {start_epoch}")
    
    history = {
        'train_loss': [],
        'val_loss': [],
        'char_accuracy': [],
        'seq_accuracy': [],
        'cer': [],
        'wer': [],
        'learning_rate': []
    }
    
    print(f"\n{'='*60}")
    print(f"STARTING TRAINING")
    print(f"{'='*60}\n")
    
    for epoch in range(start_epoch, num_epochs):
        if signal_handler.received_signal:
            print("\nStopping training early due to signal interrupt.")
            break

        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"{'='*60}")
        
        try:
            train_loss = train_one_epoch(
                model, train_loader, criterion, optimizer, encoder, device, epoch+1,
                scaler=scaler,
                accumulation_steps=1, # change from 1 to 4 if hitting GPU memory limits
                writer=writer
            )
        except (RuntimeError, KeyboardInterrupt):
            if signal_handler.received_signal:
                print("\nInterrupt caught during training loop.")
                # We caught the worker crash, but we want to proceed to save
                train_loss = 0 # Placeholder
            else:
                raise # Real error, re-raise it
        
        if signal_handler.received_signal:
            print("\nInterrupt received. Skipping validation to save immediately.")
        else:
            val_results = validate(
                model, val_loader, criterion, encoder, device, epoch+1
            )
            # Unpack validation results
            val_loss, char_acc, seq_acc, cer, wer, v_imgs, v_targs, v_preds = val_results

            writer.add_scalar('Loss/Train_Epoch', train_loss, epoch)
            writer.add_scalar('Loss/Val_Epoch', val_loss, epoch)
            writer.add_scalar('Accuracy/Character', char_acc, epoch)
            writer.add_scalar('Accuracy/Sequence', seq_acc, epoch)
            writer.add_scalar('Metric/CER', cer, epoch)
            writer.add_scalar('Metric/WER', wer, epoch)
            
            # Visual validation
            if v_imgs is not None:
                log_visual_validation(writer, epoch, v_imgs, v_targs, v_preds)

            scheduler.step(val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            writer.add_scalar('HyperParams/Learning_Rate', current_lr, epoch)
            
            history['train_loss'].append(train_loss)
            history['val_loss'].append(val_loss)
            history['char_accuracy'].append(char_acc)
            history['seq_accuracy'].append(seq_acc)
            history['cer'].append(cer)
            history['wer'].append(wer)
            history['learning_rate'].append(current_lr)
            
            final_metrics_hparams = {
                'hparam/loss': val_loss,
                'hparam/accuracy': seq_acc,
                'hparam/cer': cer
            }
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'train_loss': train_loss,
            # Handle case where validation was skipped
            'val_loss': val_loss if not signal_handler.received_signal else history['val_loss'][-1] if history['val_loss'] else 0,
            'char_accuracy': char_acc if not signal_handler.received_signal else 0,
            'seq_accuracy': seq_acc if not signal_handler.received_signal else 0,
            'best_val_loss': best_val_loss,
            'history': history,
            # Save char_map for reproducibility - ensures decoder matches training
            'char_map': getattr(model, 'char_map', None) or getattr(model, '_orig_mod', model).char_map if hasattr(model, '_orig_mod') else None,
        }
        
        torch.save(checkpoint, save_path / 'latest_model.pth')
        
        if not signal_handler.received_signal:
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(checkpoint, save_path / 'best_model.pth')
                print(f"\nSaved new best model (val_loss: {val_loss:.4f})")
            
            if seq_acc > best_seq_accuracy:
                best_seq_accuracy = seq_acc
                torch.save(checkpoint, save_path / 'best_accuracy_model.pth')
                print(f"Saved best accuracy model (seq_acc: {seq_acc:.2f}%)")
            
            if (epoch + 1) % 10 == 0:
                torch.save(checkpoint, save_path / f'checkpoint_epoch_{epoch+1}.pth')
                print(f"Saved checkpoint at epoch {epoch+1}")
        
        # Final check to break loop
        if signal_handler.received_signal:
            print("\nTraining stopped gracefully. Progress saved.")
            break
            
    # Add hyperparameters
    hparams = {
        'lr': learning_rate,
        'batch_size': batch_size,
        'image_size': str(image_size),
        'hidden_size': hidden_size,
        'num_lstm_layers': num_lstm_layers,
        'optimizer': 'Adam',
        'run_name': run_name if run_name else 'default'
    }
    if final_metrics_hparams:
        writer.add_hparams(hparams, final_metrics_hparams)
    
    writer.close()

    with open(save_path / 'training_history.json', 'w') as f:
        # Helper to convert numpy/tensor types for JSON
        def default(obj):
            if hasattr(obj, 'item'): return obj.item()
            if isinstance(obj, np.integer): return int(obj)
            if isinstance(obj, np.floating): return float(obj)
            raise TypeError
        json.dump(history, f, indent=2, default=default)
    
    print(f"\n{'='*60}")
    print(f"TRAINING COMPLETE")
    print(f"{'='*60}")
    print(f"Best validation loss: {best_val_loss:.4f}")
    print(f"Best sequence accuracy: {best_seq_accuracy:.2f}%")
    print(f"Models saved to: {save_path}")
    print(f"{'='*60}\n")
    
    return model, history, encoder, criterion, device, test_loader

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train Scale OCR Model')
    parser.add_argument('--batch-size', type=int, default=32, help='Batch size for training')
    parser.add_argument('--epochs', type=int, default=400, help='Number of epochs')
    parser.add_argument('--lr', type=float, default=0.00025, help='Learning rate')
    parser.add_argument('--data-dir', type=str, default='data', help='Directory containing data')
    parser.add_argument('--save-dir', type=str, default='models', help='Directory to save models')
    parser.add_argument('--resume', type=str, default=None, help='Path to checkpoint to resume from')
    parser.add_argument('--no-amp', action='store_true', help='Disable mixed precision training')
    parser.add_argument('--seed', type=int, default=42, help='Random seed for reproducibility')
    parser.add_argument('--run-name', type=str, default=None, help='Name for TensorBoard run')
    
    args = parser.parse_args()

    model, history, label_encoder, criterion, device, test_loader = train_model(
        batch_size=args.batch_size,
        num_epochs=args.epochs,
        learning_rate=args.lr,
        hidden_size=256,
        num_lstm_layers=2,
        image_size=(256, 64),
        save_dir=args.save_dir,
        data_dir=args.data_dir,
        resume_from=args.resume,
        use_amp=not args.no_amp,
        seed=args.seed,
        run_name=args.run_name
    )

    checkpoint_path = Path(args.save_dir) / 'best_model.pth'
    if checkpoint_path.exists():
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()

        test_epoch = len(history.get('val_loss', []))
        val_results = validate(
            model, test_loader, criterion, label_encoder, device, test_epoch
        )
        # Unpack first 5 values
        test_loss, test_char_acc, test_seq_acc, test_cer, test_wer = val_results[:5]

        print(f"\n{'='*60}")
        print(f"FINAL TEST SET RESULTS")
        print(f"{'='*60}")
        print(f"Test Loss: {test_loss:.4f}")
        print(f"Character Accuracy: {test_char_acc:.2f}%")
        print(f"Sequence Accuracy: {test_seq_acc:.2f}%")
        print(f"CER: {test_cer:.4f}")
        print(f"WER: {test_wer:.4f}")
    
    print("\nTraining finished! Next steps:")
    print(f"1. Check {args.save_dir} folder for saved models")
    print("2. Best model is saved as 'best_model.pth'")
    print("3. Use this model for inference on new videos")